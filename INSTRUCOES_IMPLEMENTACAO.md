# Instru√ß√µes de Implementa√ß√£o - Sistema de Transcri√ß√£o

## ‚ö†Ô∏è IMPORTANTE

O c√≥digo atual tem erros de sintaxe devido √†s substitui√ß√µes. Voc√™ precisar√° **reverter o arquivo `index.tsx` para a vers√£o anterior** e aplicar as mudan√ßas manualmente seguindo este guia.

## üìã Mudan√ßas Necess√°rias

### 1. Adicionar Novos Campos na Classe (linha ~141)

```typescript
private transcriptionHistory: Array<{speaker: string, text: string, timestamp: number}> = [];
private minAudioDuration = 0.05; // M√≠nimo 50ms antes de reproduzir (evita fragmenta√ß√£o)
```

### 2. Adicionar Fun√ß√£o de Reconstru√ß√£o de Frases

Adicione esta fun√ß√£o ANTES de `detectUserSpeech`:

```typescript
// Reconstruir frases picotadas usando IA
private async reconstructBrokenTranscript(speaker: string, brokenText: string): Promise<string> {
  try {
    // Se o texto for muito curto ou j√° parecer completo, retornar como est√°
    if (brokenText.length < 10 || brokenText.match(/[.!?]$/)) {
      return brokenText;
    }

    // Buscar contexto recente
    const recentHistory = this.transcriptionHistory
      .slice(-5)
      .map(t => `${t.speaker}: ${t.text}`)
      .join('\n');

    const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });
    const prompt = `Voc√™ √© um corretor de transcri√ß√µes de √°udio. A seguinte frase pode estar picotada ou incompleta devido a problemas na captura de √°udio.

Contexto da conversa:
${recentHistory}

Frase atual (${speaker}): "${brokenText}"

Sua tarefa:
1. Se a frase estiver claramente incompleta ou picotada, reconstrua-a de forma natural
2. Se a frase estiver OK, retorne ela como est√°
3. Mantenha o significado original
4. Retorne APENAS a frase corrigida, sem explica√ß√µes

Frase corrigida:`;

    const response = await ai.models.generateContent({
      model: 'gemini-2.0-flash-exp',
      contents: prompt
    });

    const reconstructed = response.text?.trim() || brokenText;
    
    if (reconstructed !== brokenText) {
      console.log(`üîß [RECONSTRUCT] Original: "${brokenText}"`);
      console.log(`‚ú® [RECONSTRUCT] Corrigido: "${reconstructed}"`);
    }

    return reconstructed;
  } catch (e) {
    console.error('‚ùå [RECONSTRUCT-ERROR]', e);
    return brokenText;
  }
}
```

### 3. Atualizar Captura de Transcri√ß√£o da IA (linha ~863)

Encontre esta se√ß√£o:
```typescript
const aiText = msg.serverContent?.modelTurn?.parts?.find(p => p.text)?.text;
if (aiText) {
  console.log(`üí¨ [${timestamp}] [TEXT-${sessionIndex}:${personaName}]`, aiText.substring(0, 80) + '...');
```

Substitua por:
```typescript
const aiText = msg.serverContent?.modelTurn?.parts?.find(p => p.text)?.text;
if (aiText) {
  console.log(`üí¨ [${timestamp}] [TEXT-${sessionIndex}:${personaName}]`, aiText.substring(0, 80) + '...');
  
  // NOVO: Reconstruir frase se estiver picotada
  const reconstructedText = await this.reconstructBrokenTranscript(personaName, aiText);
  
  // Adicionar ao hist√≥rico de transcri√ß√µes
  this.transcriptionHistory.push({
    speaker: personaName,
    text: reconstructedText,
    timestamp: Date.now()
  });
  
  // Exibir transcri√ß√£o formatada no console
  console.log(`üìù [${timestamp}] [TRANSCRIPT] ${personaName}: "${reconstructedText}"`);
  
  if (this.selectedPersonas.size === 2) {
    this.conversationHistory.push({
      speaker: personaName,
      text: reconstructedText
    });
    
    // CR√çTICO: Enviar transcri√ß√£o para a OUTRA sess√£o
    const otherSessionIndex = sessionIndex === 0 ? 1 : 0;
    const otherSession = otherSessionIndex === 0 ? this.sessionPromise : this.sessionPromise2;
    const otherPersona = Array.from(this.selectedPersonas)
      .map(id => PERSONAS.find(p => p.id === id))
      .filter(p => p)[otherSessionIndex];
    
    if (otherSession && otherPersona) {
      otherSession.then(s => {
        // BLOQUEIO: Enquanto um entrevistador fala, o outro N√ÉO recebe √°udio do microfone
        // Apenas recebe a transcri√ß√£o de texto
        const transcriptionMessage = `[CONTEXTO] ${personaName} acabou de dizer: "${reconstructedText}". Voc√™ (${otherPersona.name}) est√° acompanhando a conversa mas n√£o deve responder a menos que seja chamado diretamente ou seja sua vez de fazer perguntas.`;
        s.send(transcriptionMessage);
        console.log(`üì§ [${timestamp}] [TRANSCRIPTION] Enviado para ${otherPersona.name}: ${transcriptionMessage.substring(0, 80)}...`);
      }).catch(err => {
        console.error(`‚ùå [TRANSCRIPTION-ERROR] Erro ao enviar transcri√ß√£o:`, err);
      });
    }
  }
}
```

### 4. Atualizar Captura de Transcri√ß√£o do Usu√°rio (linha ~820)

Encontre esta se√ß√£o:
```typescript
if (userText && userText !== this.lastUserTranscript && userText.length > 15) {
  this.lastUserTranscript = userText;
  console.log(`üìù [${timestamp}] [TRANSCRIPT-${sessionIndex}] User:`, userText.substring(0, 100));
```

Substitua por:
```typescript
if (userText && userText !== this.lastUserTranscript && userText.length > 15) {
  this.lastUserTranscript = userText;
  
  // NOVO: Reconstruir frase do usu√°rio se estiver picotada
  const reconstructedUserText = await this.reconstructBrokenTranscript('Candidato', userText);
  
  console.log(`üìù [${timestamp}] [TRANSCRIPT] Candidato: "${reconstructedUserText}"`);
  
  // Adicionar ao hist√≥rico de transcri√ß√µes
  this.transcriptionHistory.push({
    speaker: 'Candidato',
    text: reconstructedUserText,
    timestamp: Date.now()
  });
  
  if (this.selectedPersonas.size === 2) {
    this.conversationHistory.push({
      speaker: 'Candidato',
      text: reconstructedUserText
    });
    
    // Enviar transcri√ß√£o do candidato para AMBAS as sess√µes
    const otherSessionIndex = sessionIndex === 0 ? 1 : 0;
    const otherSession = otherSessionIndex === 0 ? this.sessionPromise : this.sessionPromise2;
    
    if (otherSession) {
      otherSession.then(s => {
        const contextMessage = `[CONTEXTO] O candidato acabou de responder: "${reconstructedUserText}"`;
        s.send(contextMessage);
        console.log(`üì§ [${timestamp}] [USER-TRANSCRIPT] Enviado para sess√£o ${otherSessionIndex}`);
      }).catch(err => {
        console.error(`‚ùå [USER-TRANSCRIPT-ERROR]`, err);
      });
    }
  }
  
  await this.analyzeResponse(reconstructedUserText);
}
```

### 5. Adicionar Filtro Anti-Chiado (linha ~900)

Encontre esta se√ß√£o:
```typescript
// Verificar se buffer √© v√°lido
if (!buffer || buffer.duration === 0) {
  console.error(`‚ùå [${timestamp}] [BUFFER-ERROR] Buffer inv√°lido ou vazio!`);
  return;
}
```

Logo AP√ìS, adicione:
```typescript
// NOVO: Ignorar fragmentos muito pequenos (< 50ms) que causam chiado
if (buffer.duration < this.minAudioDuration) {
  console.warn(`‚ö†Ô∏è [${timestamp}] [SKIP-FRAGMENT] Fragmento muito pequeno (${(buffer.duration * 1000).toFixed(0)}ms), ignorando`);
  return;
}

// NOVO: Se a fila estiver muito grande, limpar para evitar delay
if (this.audioQueue.length > 5) {
  console.warn(`üßπ [${timestamp}] [QUEUE-CLEANUP] Fila muito grande (${this.audioQueue.length}), limpando...`);
  this.audioQueue = [];
  this.nextStartTime = 0;
}
```

### 6. Atualizar Instru√ß√µes do Sistema Dual (linha ~700)

Encontre a fun√ß√£o `initDualSessions` e atualize o `baseInstr` para:

```typescript
const baseInstr = `
  ENTREVISTA EM PAINEL - VOC√ä √â ${personas[0].name.toUpperCase()}
  
  CONTEXTO:
  Voc√™ est√° conduzindo uma entrevista junto com ${personas[1].name}.
  ${personasDesc}
  
  PERSONALIDADE GERAL: Tom ${this.personality}
  ROTEIRO: ${scriptContext}
  DURA√á√ÉO: ${this.durationMinutes} min
  CONTE√öDO: Avaliar ${skillsSummary}
  
  IMPORTANTE - SISTEMA DE TRANSCRI√á√ÉO E COMUNICA√á√ÉO:
  1. Voc√™ receber√° mensagens [CONTEXTO] com transcri√ß√µes do que ${personas[1].name} e o candidato dizem
  2. Voc√™ N√ÉO ouve o √°udio de ${personas[1].name} - apenas recebe texto
  3. Quando ${personas[1].name} falar, voc√™ receber√°: "[CONTEXTO] ${personas[1].name} acabou de dizer: ..."
  4. Quando o candidato falar, voc√™ receber√°: "[CONTEXTO] O candidato acabou de responder: ..."
  5. Use essas transcri√ß√µes para acompanhar a conversa
  
  REGRAS DE INTERA√á√ÉO:
  1. FOCO NO CANDIDATO: Sua prioridade √© interagir com o candidato, n√£o com ${personas[1].name}
  2. APRESENTA√á√ÉO INICIAL: Apenas na primeira etapa, voc√™ pode cumprimentar ${personas[1].name} brevemente (m√°ximo 1 frase)
  3. AP√ìS APRESENTA√á√ÉO: Zero intera√ß√£o com ${personas[1].name}, apenas com o candidato
  4. SE FOR CHAMADO: Se ${personas[1].name} te chamar pelo nome ou fizer uma pergunta direta, responda brevemente
  5. ALTERN√ÇNCIA: Voc√™s alternam perguntas naturalmente, sem perguntar "voc√™ quer fazer uma pergunta?"
  6. IDENTIFIQUE-SE: Sempre diga seu nome ao fazer perguntas: "Sou ${personas[0].name}, ..."
  7. CONTEXTO COMPARTILHADO: Use as transcri√ß√µes para manter continuidade na conversa
  
  EXEMPLO DE FLUXO:
  - [CONTEXTO] ${personas[1].name} acabou de dizer: "Ol√°, prazer em estar aqui"
  - Voc√™: "Prazer, ${personas[1].name}. Ol√° candidato, sou ${personas[0].name}..."
  - [CONTEXTO] O candidato acabou de responder: "Ol√°, prazer"
  - Voc√™: "√ìtimo! Vamos come√ßar..."
  
  Fale Portugu√™s do Brasil.
`;
```

E adicione no final da fun√ß√£o, ap√≥s criar as sess√µes:
```typescript
console.log('‚úÖ [SESSION] Duas sess√µes criadas com sistema de transcri√ß√£o e bloqueio de √°udio!');
console.log(`   - Sess√£o 0: ${personas[0].name} (${personas[0].voice})`);
console.log(`   - Sess√£o 1: ${personas[1].name} (${personas[1].voice})`);
console.log(`   üìù Modo: Transcri√ß√£o de texto entre IAs`);
console.log(`   üîí Bloqueio: Apenas sess√£o ativa recebe √°udio do microfone`);
console.log(`   üîß Anti-chiado: Fragmentos < 50ms s√£o ignorados`);
console.log(`   üßπ Auto-limpeza: Fila limitada a 5 √°udios`);
```

## ‚úÖ Checklist de Implementa√ß√£o

- [ ] Adicionar novos campos na classe
- [ ] Adicionar fun√ß√£o `reconstructBrokenTranscript`
- [ ] Atualizar captura de transcri√ß√£o da IA
- [ ] Atualizar captura de transcri√ß√£o do usu√°rio
- [ ] Adicionar filtro anti-chiado
- [ ] Atualizar instru√ß√µes do sistema dual
- [ ] Testar com `npm run dev`
- [ ] Verificar logs de transcri√ß√£o
- [ ] Verificar que n√£o h√° chiado
- [ ] Verificar que frases s√£o reconstru√≠das

## üß™ Como Testar

```bash
# Iniciar aplica√ß√£o
npm run dev

# Em outro terminal, filtrar logs espec√≠ficos
npm run dev | Select-String "TRANSCRIPT"
npm run dev | Select-String "SKIP-FRAGMENT"
npm run dev | Select-String "QUEUE-CLEANUP"
npm run dev | Select-String "RECONSTRUCT"
```

## üìù Logs Esperados

```
üìù [TRANSCRIPT] Alex: "Ol√°, sou Alex, Tech Lead. Prazer em estar aqui."
üì§ [TRANSCRIPTION] Enviado para Elena: [CONTEXTO] Alex acabou de dizer...
üìù [TRANSCRIPT] Candidato: "Ol√°, prazer em conhec√™-los"
‚ö†Ô∏è [SKIP-FRAGMENT] Fragmento muito pequeno (35ms), ignorando
üßπ [QUEUE-CLEANUP] Fila muito grande (6), limpando...
üîß [RECONSTRUCT] Original: "Ol√° eu sou Al..."
‚ú® [RECONSTRUCT] Corrigido: "Ol√°, eu sou Alex, Tech Lead"
```

## üéØ Resultado Final

Com essas mudan√ßas, voc√™ ter√°:

1. ‚úÖ **Transcri√ß√£o estruturada** - Formato claro de quem disse o qu√™
2. ‚úÖ **Sem chiado** - Fragmentos pequenos s√£o ignorados
3. ‚úÖ **Sem delay** - Fila √© limitada e limpa automaticamente
4. ‚úÖ **Frases completas** - IA reconstr√≥i frases picotadas
5. ‚úÖ **Contexto compartilhado** - Entrevistadores sabem o que foi dito
6. ‚úÖ **Bloqueio de √°udio** - Apenas sess√£o ativa recebe √°udio do microfone

## ‚ö†Ô∏è Notas Importantes

- A fun√ß√£o `reconstructBrokenTranscript` √© **async**, ent√£o use `await` ao cham√°-la
- O filtro de 50ms (`minAudioDuration`) pode ser ajustado se necess√°rio
- A fila √© limitada a 5 √°udios, mas pode ser ajustado
- As transcri√ß√µes s√£o salvas em `transcriptionHistory` para an√°lise posterior
